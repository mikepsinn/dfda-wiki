---
title: Adaptive Platform for Personalized Engagement
description: 
published: true
date: '2022-08-19T18:30:24.190Z'
tags: 
editor: markdown
dateCreated: '2022-07-27T20:34:01.425Z'
---

# Adaptive Platform for Personalized Engagement

## Contents

-   [1 TODO](#todo)
-   [2 Cost](#cost)
-   [3 Project Summary](#project-summary)
-   [4 Public Health Relevance Statement](#public-health-relevance-statement)
-   [5 Contact PI/ Project Leader](#contact-pi/-project-leader)
-   [6 Program Official](#program-official)
-   [7 Project Requirements](#project-requirements)
-   [8 Analytical Projects](#analytical-projects)
-   [9 Successful Open Source Projects](#successful-open-source-projects)
-   [10 Wildly Important Goal](#wildly-important-goal)
-   [11 Open Humans](#open-humans)
-   [12 Project Ideas](#project-ideas)
    -   [12.1 Diet Data Collection](#diet-data-collection)
    -   [12.2 Nifi FHIR ETL Pipelines](#nifi-fhir-etl-pipelines)
    -   [12.3 Fitbit data scraper](#fitbit-data-scraper)
    -   [12.4 Water Sampling](#water-sampling)
    -   [12.5 Health Record Conversion](#health-record-conversion)
    -   [12.6 Open Source Patient Portal](#open-source-patient-portal)
        -   [12.6.1 PrecisionFDA](#precisionfda)
-   [13 Digital Health National Highway System](#digital-health-national-highway-system)
-   [14 Community Scientist Access](#community-scientist-access)
    -   [14.1 Outcome Labels](#outcome-labels)
        -   [14.1.1 Developer Portal](#developer-portal)
        -   [14.1.2 Incentives for Developers to Use the All of Us API](#incentives-for-developers-to-use-the-all-of-us-api)
-   [15 Benefits of Allowing Contributions from the Developer Community](#benefits-of-allowing-contributions-from-the-developer-community)
-   [16 Existing Open Source Projects](#existing-open-source-projects)
-   [17 International Coordination](#international-coordination)
-   [18 Questions](#questions)
-   [19 Collection Projects vs Analysis Projects](#collection-projects-vs-analysis-projects)
    -   [19.1 References](#references)

## TODO

1.  Copy images from [https://docs.google.com/document/d/1abVA9cFzUa3Nc6OhWZ9PF04OGzlhY\_5DhoZT\_k80LiM/edit?usp=sharing](https://docs.google.com/document/d/1abVA9cFzUa3Nc6OhWZ9PF04OGzlhY_5DhoZT_k80LiM/edit?usp=sharing)
2.  General cleanup

## Cost

Award Notice Date 

Project Number 

Organization Name 

Fiscal Year 

Direct Cost 

InDirect Cost   

Total Cost 

3/6/2017 0:00 

1U24OD023163-01 

VIGNET, INC. 

2017 

$    9,966,135 

$        4,893,770 

$    14,859,905 

11/30/2018 0:00 

5U24OD023163-02 

VIGNET, INC. 

2019 

$    9,107,272 

$        5,098,712 

$    14,205,984 

9/11/2017 0:00 

3U24OD023163-01S1 

VIGNET, INC. 

2017 

$    5,527,674 

$        3,949,951 

$       9,477,625 

7/21/2018 0:00 

3U24OD023163-01S2 

VIGNET, INC. 

2018 

$    8,064,516 

$        3,935,484 

$    12,000,000 

5/30/2019 0:00 

3U24OD023163-02S1 

VIGNET, INC. 

2019 

$    4,620,309 

$        1,379,691 

$       6,000,000 

7/26/2019 0:00 

3U24OD023163-02S2 

VIGNET, INC. 

2019 

$  31,076,106 

$        8,923,112 

$    39,999,218 

7/15/2020 0:00 

3U24OD023163-02S3 

VIGNET, INC. 

2020 

$    3,662,794 

$            791,768 

$       4,454,562 

8/10/2020 0:00 

3U24OD023163-02S4 

VIGNET, INC. 

2020 

$    1,336,966 

$            242,122 

$       1,579,088 

 

 

 

 

$  73,361,772 

$      29,214,610 

$  102,576,382 

## Project Summary

The PMI Cohort Program (PMI-CP) will build a national research cohort of one million or more U.S. volunteers who are engaged as partners in a longitudinal effort to transform the understanding of factors contributing to individual health and disease. Per the Precision Medicine Initiative (PMI) Working Group Report (PMI-WGR) Recommendation 3.3: All individuals living in the U.S. should be able to volunteer for the PMI cohort. As a long-time proponent of patient-centered research, Vibrent understands that the Participant Technology Center (PTC) component of the PMI collaboration is mission-critical. Participants must be engaged through internet-enabled experiences and remain engaged. This proposal provides such an approach to Engage, Encourage, Motivate, Retain and Sustain a nationally representative Cohort. The proposal uses current technologies such as mobile phones, websites, and feature phones to achieve the objectives of the PMI Cohort Program and allow for evolving consumer technologies such as wireless sensors, wearables, and evolving science that balance innovation with robustness and scalability. We are proposing an innovative and robust approach through an Engagement and Retention Triad Model. Participant engagement and empowerment are core values for the PMI-CP and our PTC approach would enable and promote partnership between participants and researchers using PCORI Engagement Principles. Our proposal will deploy an infrastructure supported by the three pillars“ Technology, Science, and Support to engage, sustain, and scale the cohort. Each pillar will continuously improve through a process of 'measure-learn-iterate'. This will enable adaptability and personalization to ensure the long-term success of the PMI program. Through participation in collaborative research projects and large-scale consortiums, our team has the expertise to provide stewardship through coherence, integration, and synergy across the four components of the PMI-CP (PTC, CC, HPO, biobank). We will provide the infrastructure for participant engagement and communication that will scale in-depth and breadth.

## Public Health Relevance Statement

Project Narrative This research to build a cohort of one million or more U.S. volunteers engaged as partners in a longitudinal, long-term effort will transform the understanding of factors contributing to individual health and disease and enable the development of novel therapies in the future.

## Contact PI/ Project Leader

JAIN, PRADUMAN, CEO

[pj@vignetcorp.com](mailto:pj@vignetcorp.com)

## Program Official

MCCLAIN, JAMES J

[mcclainjj@mail.nih.gov](mailto:mcclainjj@mail.nih.gov)

  
 

# Project Requirements

Because of the highly sensitive nature of our data, we are bound both by regulation and oversight, but I believe there is a role for the community of publicly-oriented developers. we would like to do a pilot project that will demonstrate the potential of this approach. We need to select a project that is:

1.  Very likely to be successful
2.  Completable in a timeframe of a year or less
3.  Meaningful to our program AND to other programs
4.  Easy for non-technical people to understand the value
5.  Unlikely to run afoul of our security regulations, require Institutional Review Board oversight, require approval from our policy team, etc. (this means that code that directly touches participant data that has not been de-identified is off the table)
6.  Privacy protections: any data we share with researchers has to be tested to see if it would allow a participant to be re-identified. This can come from surprising places. For example, information about car accidents in the Electronic Health Records can be easy to connect with publicly available police records based on data. So it's not just a matter of stripping off the identifiers. We have specialists who work on this, but all data has to go through them and they have limited bandwidth.
7.  Curation: data needs to be structured, indexed, added to the data dictionary, and integrated into tools like the cohort builder. Again, a special team.
8.  Human-subjects research designation: we are under the control of an Institutional Review Board (IRB), and they grant us non-human subjects research (NHSR) designation only on close scrutiny. This designation allows us to offer our data to researchers without them having to use an IRB as well. The IRB is a serious bottleneck for the program, and we have to prioritize the data types we collect.
9.  'Missingness': data that is only available for a small part of our participant population is of less value, as researchers can't count on it being there. We emphasize data that can be available for most or all of our 300,000+ participants. Anything we collect outside of this is considered an 'ancillary' study. We are working with other NIH institutions on these studies” the largest we've committed to is a diet study, working with NIDDK, that will collect diet information from 100,000 participants. We are getting additional funding from the NIDDK to make this happen. As you might imagine, there's a lot of governance to navigate for an ancillary study, so these take the dedicated staff.
10.  Demographics: the program is addressing inequity in research, so we commit to at least 80% of our participants being underrepresented in biomedical research for some reason: age, region of the country, sexual/gender minority status, income, ancestry, etc. Additionally, we commit to at least 50% of our participants being from an ancestry (race/ethnicity) that is underrepresented in biomedical research. The data distribution needs to match as well. Collecting data from some populations (particularly people on the other side of the 'digital divide') then creates an additional burden that we address by coordinating with the health provider organizations we work with.
11.  Data access tiers: there's interesting work to do with raw data, like physician's notes, but because of the risks of reidentification, we would need to do 'remote analysis'” write the code on a public dataset (like MIMIC), and then throw the code over the wall, to be run on the real data. We would need to develop an internal team that could run and manage that process. Something we want to do long-term, but we don't yet have that staff.
12.  We enable public research: we are not a research program ourselves” we are trying to enable others to do research, so we try not to line up at the front of the data buffer. We avoid projects whose goal is scientific discovery.
13.  Accessibility: if we work with participants, we have to address different modalities of access, as well as access regulations (508 compliance) and Spanish translation.

# Analytical Projects

Collecting a new data type is very expensive, and we've made our commitments for some time, so it's an unlikely project for us. We're more likely to succeed if we focus on enhancing the value of datatypes we already collect: either for researchers or for the participants themselves. Code for researchers to use within a notebook is much easier for us to do, and could potentially be transformative. If we work on enhancing the data for the participants themselves, we have to work with the technology partners charged with that effort proof of concept may be a better place to start, with integration after we get buy-in.

  
We are particularly interested in helping researchers get more 'know-how'. There are many new techniques for dealing with data that are not widely known. I recently spoke with Ben Glicksberg at Mt. Sinai about the work he's done using Word2Vec on EHR data” a very promising approach. Showing novel approaches to the data, or showing how to link with interesting external datasets have real promise. Another example, we spoke with Heidi Rehm about the use of GnomAD ([https://gnomad.broadinstitute.org](https://gnomad.broadinstitute.org/)).

  
When the workbench launched, we demonstrated how you could use Google Facets ([https://pair-code.github.io/facets/](https://pair-code.github.io/facets/)) to explore the data. I only took that as far as showing race/ethnicity/age data, but that's the sort of thing that could be taken much further.

# Successful Open Source Projects

The most successful ones in history have been:

Linux · Ubuntu · MySQL · Apache · WordPress

What they all have in common is that they all have become a critical component for many businesses and helped people achieve selfish (not pejorative) goals.

# Wildly Important Goal

1.  Build the most diverse health database in history.
2.  Researchers will use the data to learn how our biology, lifestyle, and environment affect health to discover ways to treat and prevent disease.
3.  Convey these discoveries to individuals.

Fully realizing step 1 requires a means of sharing all the existing low-hanging data with the Data and Research Center (DRC).

Do you agree that maximizing the discovery of controllable ways to minimize symptoms would benefit from as much high-frequency longitudinal treatment, diet, and symptom data as possible?

Does the Data and Research Center (DRC) have an API?

# Open Humans

It seems that the [Open Humans](../clinical-trials/open-humans.md) Project (founded by the Harvard Personal Genome Project's George Church over a decade ago) already has good starting points for two of the project ideas you had.

[https://openhumansfoundation.org](https://openhumansfoundation.org/)

They have an open-source Fitbit scraper:

[https://github.com/OpenHumans/oh-fitbit-integration](https://github.com/OpenHumans/oh-fitbit-integration)

And the Open Humans Platform is a very modular open source tool for handling data collection, privacy, governance, and sharing.  It's broken up into a lot of separate repositories at:

[https://github.com/OpenHumans](https://github.com/OpenHumans)

They have a good track record for code review and data security so far.

What do you think about creating:

1\. A DRC API (with at least write access)

2\. An All of Us project at Open Humans that allows participants to share all their Open Humans data with the DRC via that API?

# Project Ideas

## Diet Data Collection

We know you guys have to walk a very narrow tightrope. We also know you have a million other things on your plate, so we would love to try to help make those other things easier rather than add an additional entree.

  
So we were wondering about the possibility of helping out with the NIDDK diet study you guys are already planning anyway?  Is this the project you're referring to?  

[https://commonfund.nih.gov/nutritionforprecisionhealth](https://commonfund.nih.gov/nutritionforprecisionhealth)

  
If so, it looks like diet data collection is already an objective:

  
Dietary-Intake Data Capture. There is a tremendous need to develop inexpensive and customizable dietary intake data-capture tools, including those that meet the needs of vulnerable populations, such as older adults with cognitive challenges, acutely ill patients, and people with eating disorders.  - From Objective 1-6 in [https://dpcpsi.nih.gov/sites/default/files/2020NutritionStrategicPlan\_508.pdf](https://dpcpsi.nih.gov/sites/default/files/2020NutritionStrategicPlan_508.pdf)

  
Putting specific project details aside for the moment, would you agree that observational diet data collection is a good general area of focus for an open-source project given it satisfies all of your criteria:

1.  Privacy protections: Diet data would be very difficult to trace back to the eater and observational diet-tracking data is not considered protected health information (PHI) under HIPAA
2.  Curation:  You wouldn't need an additional special team because it's already on the roadmap anyway.
3.  Human-subjects research designation:  If the open-source project focuses on observational data, the eaters wouldn't be subjects in an interventional experiment. (However, the exact same software could also be useful in interventional studies where IRB approval has been obtained.)
4.  'Missingness':  As you said, you're already working with the presumption of missingness in your diet study. Having better tools for diet data collection could actually reduce the problem of missingness by making it easier to collect data from more participants.
5.  Data access tiers:  Diet data doesn't carry the additional internal team and complexity associated with other types of data
6.  We enable public research: Diet data is much better for public research due to the reduction in privacy concerns.  Also, I'm only talking about the collection as an area of focus for this project. (My crazy analytical dreams of Outcome Labels would hopefully come later through academics and possibly a future partnership with the FDA.)
7.  Accessibility:  This issue might be more easily addressed in an open-source project as a closed-source project. For instance, Wikipedia has been voluntarily translated into 285 different languages for free by volunteers.  We doubt any government program or company would have that with the inevitable resource limitations of a closed source project.  The same sort of volunteer translation is done for many open-source projects.

We don't want to write your ear off anymore, but we have a lot of ideas for specific projects that would help to achieve the Nutrition Strategic Plan's stated goal of improving Dietary-Intake Data Capture. We also have a few more reasons below why we think that area is consistent with your first list of project requirements. But the most important reason is that our co-founder, Mike Sinn, suffered from severe anxiety, depression, inflammatory pain, and various skin conditions for decades. He was prescribed dozens of drugs to mask the symptoms, but no doctor ever asked him anything about his diet. Yet, through rigorous quantification and analysis, we identified several factors in his diet that improved symptom severity more than any drug ever had. (He is happy to show you the data sometime if you're ever interested.) Since this is likely true for millions of other people suffering from chronic diseases as well, diet seems like the most important first step.  
  
During his meeting with Dylan last week, he seemed to agree that diet data collection could be a good area of focus. If you get a chance to talk to Dylan about it or respond, we would love to hear your thoughts as well.  
  
Also, is there anyone focused on the Precision Nutrition initiative that we might be able to talk to in order to get a more precise idea about areas where they're most in need of assistance?

  
 

## Nifi FHIR ETL Pipelines

We tried, in the past, to do some open source contributions - but so far it hasn't gained traction. For example, our research platform is investing in the use of Apache NiFi. Currently, NiFi is not able to "speak" FHIR, so this past summer we prototyped adding that capability by inserting the HAPI FHIR open source project into a NiFi processor, allowing us to implement ETL pipelines with FHIR.

That looks like a really cool project!  So the objective of your video was to determine the social determinants of health.  

## Fitbit data scraper

-   A Fitbit data scraper
    -   Input: an OpenIDC authorization token allowing access to the user's Fitbit account
    -   Output: an "rsync'd" collection of their data that's accessible through the Fitbit API

Do you already have daily scheduled jobs dumping the new Fitbit/Google Fit/Apple Health data into an All of Us PostgreSQL database?

Do you have any Entity Relationship Diagrams (ERDs) of your relational storage database?

My ERD

## Water Sampling

-   Software to orchestrate at-home water sampling. (Particularly relevant for detecting incidents such as the Flint, Michigan water crisis)
    -   Participants can order an "at-home water testing kit"
    -   Participant donates the sample of water from their home and sends it to a predetermined lab for analysis
    -   The lab sends the result to our research center, which makes the data available to researchers

This would be cool, but we used to do water testing at the lab, Mike Sinn worked at ([https://labinc.com](https://labinc.com)), and each test for each analyte (lead, PCBs) typically costs at least $75. So it would be pretty expensive to test lots of houses.

It looks like there are EPA databases with lots of geographic test results that could be correlated with the health outcomes of your participants in that area.

EPA Drinking Water Data and Reports (epa.gov)

Maybe you're already doing that?

## Health Record Conversion

-   Health record conversion: OMOP to FHIR and vice versa
    -   This topic is of interest to many institutes and centers at NIH

Do any of the existing projects look promising to you?

[https://github.com/search?q=OMOP+fhir&type=Repositories](https://github.com/search?q=OMOP+fhir&type=Repositories)

Do you guys use an ELT model to initially store raw data and then do transformations upon analysis?  Or the traditional ETL model?    
  
Since you currently have a shortage of factor and outcome data and getting this data is a prerequisite for all discovery, might it be a good approach to just create an unstructured data lake that all data gets dumped into in its raw format?  Then you're certain you'll always have the original ground truth with no loss of fidelity. Then the transformation work could be postponed or outsourced to the researchers who could create transformation libraries.

## Open Source Patient Portal

-   An open source, open contribution & governance, modular, and configurable participant portal - or portion of a portal.
    -   Obviously, this is a big topic, but as long as We are just brainstorming and put audacious ideas on this list.
    -   We like the idea you mentioned in your email to us, potentially allowing the participant portal to be "pluggable" so open source developers can expand its capability

We really like this idea.  Is this legally possible? Does the NIH own the code or does Vibrent Health?

[https://reporter.nih.gov/project-details/10230444](https://reporter.nih.gov/project-details/10230444)

Vibrent -> Vanderbilt Stores Health

[Craig Nerenberg](mailto:craig@brennerwest.com) who coordinated a $17M donation to the Johns Hopkins Center for Psychedelic and Consciousness Research from Tim Ferris and Matt Mullenweg.  Matt Mullenweg created WordPress which is arguably one of the most successful open source projects ever.  It is a kind of democratized publishing.  Given his strong interest in medical research, we could try to find out how interested he would be in helping us democratize research as well by acting as an advisor in an effort to open source some part of the Participant Portal or Research Platform.

Obviously, the data is far more sensitive in the case of research.  So the pull request review would need to be extremely rigorous as it is with the Linux Kernel and Android OS.

### PrecisionFDA

Who is responsible for coordinating All of Us with PrecisionFDA?  It seems like there's some overlap between the All of Us Research Platform and PrecisionFDA.  Will PrecisionFDA be able to use data collected by All of Us?

-   We could discuss the potential for APIs, but the topic of data donation and data linkage more generally
-   American Communities Survey - Median Income from Census Tract - Disease correlations

# Digital Health National Highway System

ONC - Office of the National Coordinator

[https://careevolution.com/](https://careevolution.com/) - the highway of health data exchange

So the national highway system is a "public good" that enables private sector businesses to cooperate and satisfy human needs.  The economy would be far less efficient if we had a bunch of proprietary roads that only allowed specific brands of cars to travel to specific locations. However, that's exactly what we have now when it comes to healthcare data.

Is the NIH and/or All of Us best suited to create a national highway system for health data?  Or is that someone else's job?

If it's within your scope, would an All of Us API be the national health highway and a developer portal be the DMV issuing driver's licenses?

-   The interstate highway system as a model for US health care - STAT
-   Bipartisan Bill Would Standardize Public Health Data and Bolster Sharing
-   About NCHS - NCHS Fact Sheets - NCHS Nutrition Data

# Community Scientist Access

We are excited about the potential of a project like this because our research program has a mission goal and a desire to expand access for community scientists, but few tangible ways to start. Perhaps our conversations can lay out some of the desires and expectations of a community scientist, and further that goal.

## Outcome Labels

The core objective of All of Us is to make new discoveries that will help people prevent and alleviate disease.  

Discovering the long-term health effects of the hundreds of chemicals we consume through our diet seems like the most valuable target for a crowdsourcing project such as yours for the following reasons:

1.  Fewer Privacy Issues - Diet-tracking data is not considered protected health information (PHI) under HIPAA
2.  Diet is Controllable - What a person eats is within the control of the individual, so knowledge of the long-term effects of different foods would be actionable insights.
3.  No Financial Incentive for Controlled Clinical Trials - Patentable molecules can recoup the $50k/subject costs of clinical trials, but unpatentable foods and additives cannot.  This leaves crowdsourced observational research as the only viable avenue for discovery.
4.  Lots of Variables Require Lots of Participants - As your cohort will be the largest in history, it is most likely to successfully apply the law of large numbers to cancel out random confounding variable noise that is inevitable in observational research.
5.  This would be valuable to the FDA as well.

To make these discoveries actionable for individuals, the FDA (or [https://precision.fda.gov](https://precision.fda.gov/)) may want to provide "Outcome Labels"  that instead list the degree to which the product is likely to improve or worsen specific health outcomes or symptoms. Once we can combine epidemiological data on the prevalence of diseases such as Alzheimer's, we'll also be able to see which foods and drugs are more likely to increase the long-term likelihood of developing these diseases.

We have generated these "Outcome Labels" for thousands of foods and drugs at [https://studies.dfda.earth/](https://studies.dfda.earth/).  

The data was derived through manual input or 3rd party imports from about 10,000 users of our app [https://app.curedao.org/](https://app.curedao.org/).   
However, most of the results currently suck due to the fact that although there are 10,000 participants overall, any given study on a predictor/outcome relationship might only have a few participants. So it would be ideal to collect data from millions of participants.  

It would be great if All of Us could eventually take advantage of the massive silos of drug, food, and supplement purchase records sitting uselessly in Amazon, Instacart, Shipt, Walgreens, EHR, and CVS siloed databases.

### Obtain Data

The first step to producing these actionable insights would be making it easy for developers of the 50k healthcare apps to share their data with you.  

That would require an All of Us Developer Portal that gave developers an OAuth2 client id and secret. Then they could put a "Share Your Data with All of Us" button in their app that sent them to login with all of us and a consent screen where they could indicate if they want to allow the client app to write data to their All of Us account.

Clicking on that button in a participating app would bring the user to the All of Us OAuth consent screen like this:

### Developer Portal

An open-source Developer Portal might be a good pilot project because it just issues developers their API client id and secret and doesn't deal with any patient data.

There's an open-source full OAuth2 server implementation that could be used as the basis for the developer portal and would allow it to be up and running quickly

[https://laravel.com/docs/8.x/passport](https://laravel.com/docs/8.x/passport)

So that helps to satisfy the "year or less" timeline constraint.  

### Incentives for Developers to Use the All of Us API

The question then is the incentive for developers to do this.  

-   Write-Only: If the access is write-only, it seems like there might need to be small grants to developers to finance the implementation.  Maybe the amount of support would be based on the amount of data they provide?
-   Read-access to the data provided by the client app: If the apps are also allowed to read back at only their own user data they've stored in your database, then you could act as a backend-as-a-service (BaaS) like Firebase ([https://firebase.google.com/](https://firebase.google.com/)).
-   User-granted read-access to All of Us data from other apps or analysis results:  If the apps can also use All of Us data from other sources to provide value to the user, this would provide even more incentive for developers to integrate. So you would be like a Digital Health backend-as-a-service (DHBaaS)

Even if those incentives weren't possible or sufficient, a more open-source and collaborative ecosystem would be highly beneficial to all stakeholders. We're all humans who suffer from or care about someone suffering from a disease. It seems like the [All of Us research program](../clinical-trials/all-of-us-research-program.md) is most uniquely positioned to be the catalyst for the ecosystem below.  Would you agree?

Would you agree that a Developer Portal that would pave the way to the collection of high-frequency diet tracking data would satisfy these requirements?

-   Very likely to be successful
-   Completable in a timeframe of a year or less
-   Meaningful to our program AND to other programs
-   Easy for non-technical people to understand the value
-   Unlikely to run afoul of our security regulations, require Institutional Review Board oversight, require approval from our policy team, etc. (this means that code that directly touches participant data that has not been de-identified is off the table)

Or are there better avenues?

# Benefits of Allowing Contributions from the Developer Community

Thank you for your great work with All of Us. We believe it has more potential to reduce suffering per dollar spent than any other public health initiative in history.

However, it seems like its potential is currently being constrained by not taking full advantage of the 7 million open source developers around the world (who would benefit from its success).

  
We have contributed as much data as we can to All of Us through your Fitbit connector and surveys.  Currently, you don't have integrations with any of my healthcare provider's EHR systems.

  
We built an open-source app called Crowdsourcing Cures that collects and aggregates data on symptoms, diet, sleep, exercise, weather, medication, and anything else from dozens of life-tracking apps and devices. We have about a decade of high-frequency longitudinal data from over 10,000 users that would be very valuable to researchers.

However, since the All of Us platform appears to be closed-source, We can't build a data-sharing integration for you. And there's no public Application Programming Interface (API)) that would allow me to send my data to you either.

By creating a public API and enabling EHR systems and digital health apps to use the All of Us database for storage, you could establish de-facto data format standards that would finally allow all digital health systems to talk to each other.

Additionally, by making the All of Us platform a global open source project, you could eliminate the waste of developer effort that's currently being spent building the exact same feature for different companies or different national health systems. Instead, all those development hours could be spent improving the same code base.

Does creating any of the following seem like a good idea to you?

-   Open-Source software repository for the patient portal to allow developers to enhance data collection capabilities
-   Open-Source software repository for the research platform to allow developers to enhance data analysis capabilities
-   A public Application Programming Interface (API) to allow the All of Us database to serve as a global back end for digital health software

# Existing Open Source Projects

-   microsoft/fhir-server: A service that implements the FHIR standard
-   openemr/openemr: OpenEMR is the most popular open-source electronic health records and medical practice management solution. OpenEMR's goal is a superior alternative to its proprietary counterparts.
-   hapifhir/hapi-fhir: ðŸ”¥ HAPI FHIR - Java API for HL7 FHIR Clients and Servers
-   synthetichealth/synthea: Synthetic Patient Population Simulator
-   OHDSI/CommonDataModel: Definition and DDLs for the OMOP Common Data Model (CDM)
-   Learn How to Use HADES

# International Coordination

-   UK BioBank

# Questions

Q: Do you have a high-level diagram of the overall architecture of the participant portal - Vanderbilt data lake - research platform?

A:

Q: Do you have any links to more information about the mood tracking app you plan to introduce? Is it built? Will it be part of the participant portal or a separate entity? Who's building it?

A:

Q: Do you have any links to more information about the precision nutrition project where people would live at the NIH?

A:

Q: Do you currently have a private API that could potentially receive and store participant data?

A:

Q: Does All of Us have a public technical question-and-answer forum or wiki that developers can use to ask questions about technical aspects of your project?

A:

-   Market research to identify the most common diet tracking apps
-   Describe OH partnership to scrape
-   Do you want to know more about how diet impacts your health?

# Collection Projects vs Analysis Projects

Also, you brought up some very interesting potential avenues regarding analytical projects. So we were thinking about general collection vs analysis projects with respect to your initially stated requirements, and I thought I'd share my comparison if you're interested.

  
For purposes of comparison, We assumed that if you did want to pursue a diet data collection project, it would be in the form of a diet tracking app. (However, other options could include importers importing diet data from existing apps and data sources.)

  
1\. Meaningful to our program AND to other programs

This is a very good point. The most successful open source projects in history include:

Linux · Ubuntu · MySQL · Apache · WordPress

What they all have in common is that they all have become a critical component for many businesses and helped people achieve selfish (not pejorative) goals.

  
There is not currently a successful open-source diet tracking app that We can find. Yet, there are a ton of government health programs (i.e. foreign equivalents of the FDA and NIH), academic institutions, digital health companies, dieticians, and health systems around the world that would benefit from an easy way for their citizens, customers, or patients to collect and share diet data.

  
So like with WordPress, there could be an incentive for contributions from a large base of organizations or developers motivated by solving their own problems.

  
2\. Easy for non-technical people to understand the value

We have found that the Outcome Labels idea described below has been the most effective way to convey the value of my analysis projects.  However, it seems like it's usually pretty challenging to convey the value of most analytical projects to non-technical people.  Whereas millions of people already use diet-tracking apps indicating that they already understand the value in that.

  
3\. Unlikely to run afoul of our security regulations

Analysis of the spectrum of data needed to derive value for patients is fraught with all the privacy issues you mentioned.  Thus it might be impossible to make the required data easily accessible to open source contributors enough to inspire broad contribution.  

  
4\. Very likely to be successful in a timeframe of a year or less

Success for an Analysis Project = Make discoveries that can help people prevent or treat disease

The order of operations is such that we need data before we can analyze it to derive actionable insights. As a participant, the only longitudinal data We can share with you at this time is Fitbit data.  Without any longitudinal symptom data or diet/supplement data, it's impossible for me to achieve the goal of discovering what we can do to improve our symptoms.  

  
Success for a Collection Project = Collect factor or outcome data that can be analyzed

We are not necessarily saying we should use my app as a starting point, but We have already created an open-source app that can track diet.  

Repo: [https://github.com/curedao/curedao-web-android-chrome-ios-app-template](https://github.com/curedao/curedao-web-android-chrome-ios-app-template)

App: [https://app.curedao.org/](https://app.curedao.org/)

  
My app has a lot of additional functionality, but it could easily be removed.  

  
Arguments against using it as a starting point are that:

-   there's a ton of room for UI improvement
-   the code is currently over complicated and under-documented

However, it's been able to collect about 12 million data points so far, so at least it works.

  
We've tried to find other open-source diet tracking apps to see if there were better starting points ([https://github.com/search?q=diet+tracker&type=Repositories](https://github.com/search?q=diet+tracker&type=Repositories)) but I haven't found any with much traction.  

  
However, this is a very interesting open food database ([https://github.com/openfoodfacts](https://github.com/openfoodfacts)) that has about a million foods. We have imported the USDA database and nutrition facts, but it's somewhat incomplete.  

  
Even if you wanted to completely start from scratch, assuming we used some hybrid Android/iOS framework like Ionic or React Native, and given my previous experience, We are confident we could have a decent app within a year.

## References

-   [https://reporter.nih.gov/project-details/10230444](https://reporter.nih.gov/project-details/10230444)